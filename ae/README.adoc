[[graviteeio-alert-engine-helm-chart]]
== Gravitee.io Alert Engine Helm Chart

*Chart supported versions: 1.0.x and higher*

=== Components

This chart will deploy the following:

* Gravitee.io Alert Engine

=== Kubernetes

AE embeds Hazelcast to propagate and process events between each node. In order to make Hazelcast work best when embedded and deployed under a Kubernetes cluster, we pre-configured the auto-discovery to work with the Kubernetes API.

[quote]
____
Kubernetes API mode means that each node makes a REST call to Kubernetes Master in order to discover IPs of PODs (with Hazelcast members).]
____

In order to make it work, you need to grant access to the Kubernetes API.

[source,bash]
----
$ kubectl apply -f https://raw.githubusercontent.com/gravitee-io/helm-charts/master/ae/rbac.yml
----

If you want to let Helm to create the Service Account with required cluster role while installating the Chart, use `--set engine.managedServiceAccount=true`

Please note that `managedServiceAccount` is enabled by default and so, you'll have to switch it off if you want to manage the Service Account by yourself.

WARNING: rbac.yml comes with default `graviteeio` namespace. Make sure to use the right namespace if you have overridden it.

[IMPORTANT]
====
Alert Engine need a https://docs.gravitee.io/ee/ee_license.html[license] to work. You can define it by:

* fill the `license.key` field in the `values.yml` file.
* add helm arg: `--set license.key=<license.key in base64>`

To get the license.key value, encode your file `license.key` in `base64`:

* linux: `base64 -w 0 license.key`
* macOS: `base64 license.key`

Example:

[source,bash]
----
export GRAVITEESOURCE_LICENSE_B64="$(base64 -w 0 license.key)"

helm install \
  --set license.key=${GRAVITEESOURCE_LICENSE_B64} \
  graviteeio-ae \
  graviteeio/ae
----
====

=== Installing

* Add the Gravitee.io helm charts repo
+
....
$ helm repo add graviteeio https://helm.gravitee.io
....
* Install it
+
....
$ helm install --name graviteeio-ae graviteeio/ae
....

=== Create a chart archive

To package this chart directory into a chart archive, run:

....
$ helm package .
....

=== Installing the Chart

To install the chart from the Helm repository with the release name
`+graviteeio-ae+`:

[source,bash]
----
$ helm install --name graviteeio-ae graviteeio/ae
----

To install the chart using the chart archive, run:

....
$ helm install ae-1.0.0.tgz
....

=== Configuration

The following tables list the configurable parameters of the Gravitee.io
Alert Engine chart and their default values.

==== Shared configuration

To configure common features such as:

* chaos testing (see
https://github.com/kubernetes/charts/tree/master/stable/chaoskube[chaoskube]
chart)

[cols=",,",options="header",]
|===
|Parameter |Description |Default
|`+chaos.enabled+` |Enable Chaos test |false
|===

==== Gravitee Alert Engine

[cols=",,,",options="header",]
|===
|Key |Type |Default |Description
|engine.authentication.adminPassword |string |`+"adminadmin"+` |

|engine.authentication.enabled |bool |`+true+` |

|engine.autoscaling.enabled |bool |`+true+` |

|engine.autoscaling.maxReplicas |int |`+3+` |

|engine.autoscaling.minReplicas |int |`+1+` |

|engine.autoscaling.targetAverageUtilization |int |`+50+` |

|engine.autoscaling.targetMemoryAverageUtilization |int |`+80+` |

|engine.enabled |bool |`+true+` |

|engine.image.pullPolicy |string |`+"Always"+` |

|engine.image.repository |string |`+"graviteeio/ae-engine"+` |

|engine.ingress.annotations."kubernetes.io/app-root" |string |`+"/"+` |

|engine.ingress.annotations."kubernetes.io/ingress.class" |string
|`+"nginx"+` |

|engine.ingress.annotations."kubernetes.io/rewrite-target" |string
|`+"/"+` |

|engine.ingress.annotations."nginx.ingress.kubernetes.io/enable-rewrite-log"
|string |`+"true"+` |

|engine.ingress.annotations."nginx.ingress.kubernetes.io/ssl-redirect"
|string |`+"false"+` |

|engine.ingress.enabled |bool |`+true+` |

|engine.ingress.hosts[0] |string |`+"ae.example.com"+` |

|engine.ingress.path |string |`+"/"+` |

|engine.ingress.tls[0].hosts[0] |string |`+"ae.example.com"+` |

|engine.ingress.tls[0].secretName |string |`+"api-custom-cert"+` |

|engine.logging.debug |bool |`+false+` |

|engine.logging.file.enabled |bool |`+true+` |

|engine.logging.file.encoderPattern |string
|`+"%d{HH:mm:ss.SSS} [%thread] [%X{api}] %-5level %logger{36} - %msg%n"+`
|

|engine.logging.file.rollingPolicy |string
|`+"\u003crollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"\u003e\n    \u003c!-- daily rollover --\u003e\n    \u003cfileNamePattern\u003e${gravitee.home}/logs/gravitee_%d{yyyy-MM-dd}.log\u003c/fileNamePattern\u003e\n    \u003c!-- keep 30 days' worth of history --\u003e\n    \u003cmaxHistory\u003e30\u003c/maxHistory\u003e\n\u003c/rollingPolicy\u003e\n"+`
|

|engine.logging.graviteeLevel |string |`+"DEBUG"+` |

|engine.logging.stdout.encoderPattern |string
|`+"%d{HH:mm:ss.SSS} [%thread] [%X{api}] %-5level %logger{36} - %msg%n"+`
|

|engine.name |string |`+"engine"+` |

|engine.reloadOnConfigChange |bool |`+true+` |

|engine.replicaCount |int |`+1+` |

|engine.resources.limits.cpu |string |`+"500m"+` |

|engine.resources.limits.memory |string |`+"512Mi"+` |

|engine.resources.requests.cpu |string |`+"200m"+` |

|engine.resources.requests.memory |string |`+"256Mi"+` |

|engine.service.externalPort |int |`+82+` |

|engine.service.internalPort |int |`+8072+` |

|engine.service.internalPortName |string |`+"http"+` |

|engine.service.type |string |`+"ClusterIP"+` |

|engine.ssl.clientAuth |bool |`+false+` |

|engine.ssl.enabled |bool |`+false+` |

|engine.type |string |`+"Deployment"+` |

|license.key |string |license.key file encoded in base64 |
|===

Specify each parameter using the `+--set key=value[,key=value]+`
argument to `+helm install+`.

Alternatively, a YAML file that specifies the values for the parameters
can be provided while installing the chart. For example,

[source,bash]
----
$ helm install --name my-release -f values.yaml gravitee
----

____
*Tip*: You can use the default values.yaml
____

==== Recommendations for a production environment

For a production ready environment, we recommend to apply the following settings.

===== Memory

For large environment handling a lot of events we recommend specifying enough memory available for the JVM to be able to process all events in real time.

```yaml
engine:
  env:
     - name: GIO_MIN_MEM
       value: 1024m
     - name: GIO_MAX_MEM
       value: 1024m
     - name: gravitee_ingesters_ws_compressionSupported
       value: "true"
```

You must also adapt the memory request and limit at pod level. When using 1Go at JVM level, we recommend to set 1.5Go at pod level to make sure the pod will not run out of memory and get killed.

```yaml
  resources:
    limits:
      memory: 1.5Gi
    requests:
      memory: 1.5Gi
```

===== CPU

The following default values should be enough in most cases and should allow handling approximately 2000 events per seconds with only 2 pods (see autoscaling section to specify min and max pods).

```yaml
  resources:
    limits:
      cpu: 1000m
    requests:
      cpu: 500m
```

===== Autoscaling

By default, there is only 1 AE pod started (up to 3 pods). To make the system error proofed and handle more events at high throughput, you may configure the autoscaler with a minimum of 2 pods and maybe increase the number of maximum pods.

```yaml
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 5
    targetAverageUtilization: 50
    targetMemoryAverageUtilization: null
```

NOTE: You may also disable the autoscaling based on memory average utilization except if you have a specific metrics server able to calculate the memory used by a JVM running in a container.

===== Readiness and liveness probes

Depending on your usage of AE, you can also fine tune the different probes used by the cluster to determine the current status of each AE pod.

The default values are quite optimized to get a good ratio between fast and reliability.

```yaml

# This probe is use only during startup phase
startupProbe:
  tcpSocket:
    port: http # Same as engine.service.internalPortName
  initialDelaySeconds: 30
  periodSeconds: 5
  failureThreshold: 20

# This probe is used to determine if the pod is still alive.
livenessProbe:
  tcpSocket:
    port: http # Same as engine.service.internalPortName
  periodSeconds: 10
  failureThreshold: 5

# This probe is used to determine if the pod can still handle traffic. If not, it will be removed from the service and not reachable until it is ready again.
readinessProbe:
  tcpSocket:
    port: http # Same as engine.service.internalPortName
  periodSeconds: 5
  failureThreshold: 3
```

Depending on the amount of cpu you give to each pod you should be able to change the different settings of the startupProbe such as `initialDelaySeconds`.

TIP: The more processors you have, the faster the server will start, the lower you can set the `initialDelaySeconds` value.

===== Enable compression

To optimise network transfer between Gravitee API Management or Access Management and Alert Engine, it could be useful to enable compression.

IMPORTANT: Compression comes with cpu costs (on both client and server sides). You may balance the choice analyzing cpu cost versus network and response time improvements.

```yaml
engine:
  env:
     - name: gravitee_ingesters_ws_compressionSupported
       value: "true"
```

WARNING: make sure `alerts.alert-engine.ws.tryCompression` is set to true on the APIM / AM side
